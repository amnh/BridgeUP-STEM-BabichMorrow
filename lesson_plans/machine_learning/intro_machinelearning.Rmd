---
title: "Hello machine learning!"
author: Cecina Babich Morrow
output:
  github_document:
    html_preview: false
---

Material for this lesson was adapted from https://machinelearningmastery.com/machine-learning-in-r-step-by-step/.

## Iris data

To get a feel for machine learning in R, we are going to start with a project on a famous dataset in R: the iris dataset. The iris dataset was introduced by a British biologist named Ronald Fisher in 1938, but the data was actually collected by Edgar Anderson. The dataset consists as 50 samples from each of 3 species of iris: *Iris setosa*, *Iris virginica*, and *Iris versicolor*. For each flower, Anderson measured the length and width of the sepals and petals.

R allows us to look at the iris data directly, without having to download it from online:

```{r}
data(iris)
```

**Try it yourself:** View the iris dataset.

```{r}

```

### Exploratory data analysis

As we learned with our sloth data, it's useful to spend some time plotting your data and looking for patterns (otherwise you could end up with sloths in the ocean). This process of exploratory data analysis is important for all data projects. In this machine learning project, we are working with numerical data that is not spatial, so you'll have the opportunity to do some exploratory data analysis that doesn't involve maps. This is also your chance to work with some of the statistics that R can do.

**Try it yourself:** This is your chance to play with R! See if you can figure out how to complete the following challenges:

+ Make a histogram
+ Find the mean sepal length of all the species
+ Find the mean petal length for each species separately
+ Find a standard deviation
+ Make a boxplot of one of the variables. See if you can create separate boxes for each of the species
+ Make a scatterplot of two of the variables, for example petal width on the x-axis and petal length on the y-axis

Some functions you might want to use:
+ `hist()`
+ `mean()`
+ `favstats()` (you need the `mosaic` package for this function, but it's super useful)
+ `boxplot()`
+ `plot()` (put your x variable first and your y variable second)

```{r}

```


## `caret` package

For this exercise, we are going to be using the `caret` package in R, which allows you to run hundreds of different machine learning algorithms, visualize the results, and compare models.

**Try it yourself:** Install and load the `caret` package:

```{r}

```

## Machine learning time

### Create a validation dataset

In machine learning, it's often useful to have a set of training data and a set of test/validation data. The training data is what you use to "teach"" the algorithm in supervised learning. After you create your model, you can test it on the validation data to check that it performs well on data that the model has not seen before. For this project, we are going to split our iris data: 80% will be training data and 20% will be validation data.

**Try it yourself:** Look at the help menu for the function `createDataPartition()`. This function from the `caret` package separates data into test and training sets.

```{r}
# create a list of 80% of the rows in the original dataset to use for training
training_rows <- createDataPartition(iris$Species, p = 0.80, list = FALSE)
```

**Try it yourself:** Find the length of `validation_rows`. Is this the number you expect? Why/why not?

```{r}

```

We want to take those rows of our data to use as our training set.

**Try it yourself:** Create a dataframe `training` consisting of the rows that ARE in `training rows`. Hint: you'll need to use subsetting.

```{r}

```

Now we need to set aside the remaining 20% of the data for validation. We want the validation dataset to be the rows of `iris` that are not in `training_rows`.

**Try it yourself:** Create a dataframe `validation` consisting of the rows NOT in `training_rows`. Hint: you'll need to use subsetting and you may want to use the - sign (Google is your friend!) -- this is the opposite of what you just did to create `training`.

```{r}
validation <-
```

### Summarize the training data



